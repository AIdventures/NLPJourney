{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a causal language model from scratch\n",
    "\n",
    "We’ll train a completely new model from **scratch**. This is a good approach to take if you have a **lot of data** and it is **very different from the pretraining data used for the available models**. However, it also requires considerably more compute resources to pretrain a language model than just to **fine-tune an existing one**. Examples where it can make sense to train a new model include for datasets consisting of musical notes, molecular sequences such as DNA, or programming languages. This task of text generation is best addressed with auto-regressive or causal language models such as GPT-2.\n",
    "\n",
    "In this section we will build a scaled-down version of a code generation model: we’ll focus on one-line completions instead of full functions or classes, using a subset of Python code. When working with data in Python you are in frequent contact with the Python data science stack, consisting of the matplotlib, seaborn, pandas, and scikit-learn libraries. When using those frameworks it’s common to need to look up specific commands, so it would be nice if we could use a model to complete these calls for us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gathering the data\n",
    "\n",
    "Python code is abundantly available from code repositories such as GitHub, which we can use to create a dataset by scraping for every Python repository. This was the approach taken in the [Transformers textbook](https://learning.oreilly.com/library/view/natural-language-processing/9781098136789/) to pretrain a large GPT-2 model. Using a GitHub dump of about 180 GB containing roughly 20 million Python files called `codeparrot`, the authors built a dataset that they then shared on the [Hugging Face Hub](https://huggingface.co/datasets/transformersbook/codeparrot).\n",
    "\n",
    "However, training on the full corpus is time- and compute-consuming, and we only need the subset of the dataset concerned with the Python data science stack. So, let’s start by **filtering the `codeparrot` dataset** for all files that include any of the libraries in this stack. Because of the dataset’s size, we want to **avoid downloading** it; instead, we’ll use the **streaming feature to filter it on the fly**. To help us filter the code samples using the libraries we mentioned earlier, we’ll use the following function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def any_keyword_in_string(string: str, keywords: list[str]) -> bool:\n",
    "    \"\"\"\n",
    "    Check if any of the keywords are in the string\n",
    "\n",
    "    Parameters:\n",
    "        string (str): The string to check\n",
    "        keywords (list[str]): The keywords to check for\n",
    "\n",
    "    Returns:\n",
    "        bool: True if any of the keywords are in the string, False otherwise\n",
    "    \"\"\"\n",
    "    for keyword in keywords:\n",
    "        if keyword in string:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s test it on two examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False True\n"
     ]
    }
   ],
   "source": [
    "filters = [\"pandas\", \"sklearn\", \"matplotlib\", \"seaborn\"]\n",
    "example_1 = \"import numpy as np\"\n",
    "example_2 = \"import pandas as pd\"\n",
    "\n",
    "print(\n",
    "    any_keyword_in_string(example_1, filters),\n",
    "    any_keyword_in_string(example_2, filters)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use this to create a function that will stream the dataset and **filter the elements we want**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_streaming_dataset(dataset, filters, max_samples=30000):\n",
    "    \"\"\"\n",
    "    Filter a streaming dataset\n",
    "\n",
    "    Parameters:\n",
    "        dataset (Dataset): The streaming dataset to filter\n",
    "        filters (list[str]): The keywords to filter the dataset on\n",
    "        max (int): The maximum number of samples to filter\n",
    "\n",
    "    Returns:\n",
    "        Dataset: The filtered dataset\n",
    "\n",
    "    Notes\n",
    "        - Filtering the full dataset can take 2-3h depending on your\n",
    "        machine and bandwidth.\n",
    "    \"\"\"\n",
    "    filtered_dict = defaultdict(list)  # dict of lists\n",
    "    total = 0  # Counting the total number of samples\n",
    "    total_filtered = 0  # Counting the number of ok samples\n",
    "    for sample in tqdm(iter(dataset)):  # Iterating over the dataset\n",
    "        total += 1  # Incrementing the total count\n",
    "        # Check if any of the filters are in the content\n",
    "        if any_keyword_in_string(sample[\"content\"], filters):\n",
    "            # If so, append the sample to the filtered_dict\n",
    "            for k, v in sample.items():  # Iterate over the key-value pairs\n",
    "                filtered_dict[k].append(v)  # Append the data from sample\n",
    "            total_filtered += 1\n",
    "        # If we have filtered enough samples, break the loop\n",
    "        if max_samples!=-1 and total_filtered >= max_samples:\n",
    "            break\n",
    "\n",
    "    # Print the percentage of data that is kept after filtering\n",
    "    print(f\"{len(filtered_dict['content'])/total:.2%} of data after filtering.\")\n",
    "    # Return a new Dataset from the filtered_dict\n",
    "    return Dataset.from_dict(filtered_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can simply apply this function to the streaming dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75765d66029f49db95815532ba3b4a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/183 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "927887it [09:34, 1615.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.23% of data after filtering.\n"
     ]
    }
   ],
   "source": [
    "# This cell will take a very long time to execute, so you should skip it and go to\n",
    "# the next one!\n",
    "from datasets import load_dataset\n",
    "\n",
    "split = \"train\"  # \"valid\"\n",
    "filters = [\"pandas\", \"sklearn\", \"matplotlib\", \"seaborn\"]\n",
    "\n",
    "data = load_dataset(\n",
    "    f\"transformersbook/codeparrot-{split}\",\n",
    "    split=split,\n",
    "    streaming=True\n",
    ")\n",
    "filtered_data = filter_streaming_dataset(data, filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we set `max_samples` to \"all\" (-1), this leaves us with about 3% of the original dataset, which is still quite sizable — the resulting dataset is 6 GB and consists of **600,000 Python scripts**!\n",
    "\n",
    "> Pretraining the language model will take a while. We suggest that you first run the training loop on a sample of the data by uncommenting the two partial lines above, and make sure that the training successfully completes and the models are stored. Nothing is more frustrating than a training run failing at the last step because you forgot to create a folder or because there’s a typo at the end of the training loop!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and validation splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['repo_name', 'path', 'copies', 'size', 'content', 'license'],\n",
       "        num_rows: 27000\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['repo_name', 'path', 'copies', 'size', 'content', 'license'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets = filtered_data.train_test_split(test_size=0.1)\n",
    "# rename \"test\" partition to \"valid\"\n",
    "raw_datasets['valid'] = raw_datasets.pop('test')\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s look at an example from the dataset. We’ll just show the first 200 characters of each field:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REPO_NAME: xunyou/vincent\n",
      "PATH: examples/area_chart_examples.py\n",
      "COPIES: 11\n",
      "SIZE: 1947\n",
      "CONTENT: # -*- coding: utf-8 -*-\n",
      "\"\"\"\n",
      "\n",
      "Vincent Area Examples\n",
      "\n",
      "\"\"\"\n",
      "\n",
      "#Build an Area Chart from scratch\n",
      "\n",
      "from vincent import *\n",
      "import pandas.io.data as web\n",
      "all_data = {}\n",
      "for ticker in ['AAPL', 'GOOG', 'IBM', 'YHOO\n",
      "LICENSE: mit\n"
     ]
    }
   ],
   "source": [
    "for key in raw_datasets[\"train\"][0]:\n",
    "    print(f\"{key.upper()}: {raw_datasets['train'][0][key][:200]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the content field contains the code that we want our model to train on. Now that we have a dataset, we need to prepare the texts so they’re in a format suitable for pretraining."
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "The first step will be to **tokenize the data**, so we can use it for training. Since our goal is to mainly autocomplete short function calls, we can keep the **context size relatively small**. This has the benefit that we can train the model much faster and it requires significantly less memory. If it is important for your application **to have more context** (for example, if you want the model to write unit tests based on a file with the function definition), make sure you increase that number, but also keep in mind that this comes with a greater GPU memory footprint. For now, let’s fix the context size at 128 tokens, as opposed to the 1,024 or 2,048 used in GPT-2 or GPT-3, respectively.\n",
    "\n",
    "Most documents contain many more than 128 tokens, so simply **truncating the inputs to the maximum length** would eliminate a large fraction of our dataset. Instead, we’ll use the `return_overflowing_tokens` option to tokenize the whole input and **split it into several chunks**. We’ll also use the `return_length` option to return the length of each created chunk automatically. Often the last chunk will be smaller than the context size, and we’ll get rid of these pieces to avoid padding issues; we don’t really need them as we have plenty of data anyway.\n",
    "\n",
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input IDs length (number of chunks): 20\n",
      "Input chunk lengths: [128, 128, 128, 128, 73, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 17]\n",
      "Chunk mapping: [0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "context_length = 128\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"huggingface-course/code-search-net-tokenizer\"\n",
    ")\n",
    "\n",
    "outputs = tokenizer(\n",
    "    raw_datasets[\"train\"][:2][\"content\"],  # use two samples\n",
    "    truncation=True,\n",
    "    max_length=context_length,\n",
    "    return_overflowing_tokens=True,\n",
    "    return_length=True,\n",
    ")\n",
    "\n",
    "print(f\"Input IDs length (number of chunks): {len(outputs['input_ids'])}\")\n",
    "print(f\"Input chunk lengths: {(outputs['length'])}\")\n",
    "print(f\"Chunk mapping: {outputs['overflow_to_sample_mapping']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we get 31 segments in total from those two examples. Looking at the chunk lengths, we can see that the chunks at the ends of both documents have less than 128 tokens (110 and 12, respectively). These represent just a small fraction of the total chunks that we have, so we can **safely throw them away**. With the `overflow_to_sample_mapping` field, we can also reconstruct which chunks belonged to which input samples.\n",
    "\n",
    "With this operation we’re using a handy feature of the `Dataset.map()` function in Hugging Face Datasets, which is that it does not require one-to-one maps; we can create batches with more or fewer elements than the input batch. This is useful when doing operations like data augmentation or data filtering that change the number of elements. In our case, when tokenizing each element into chunks of the specified context size, we create many samples from each document. We just need to make sure to delete the existing columns, since they have a conflicting size. If we wanted to keep them, we could repeat them appropriately and return them within the `Dataset.map()` call.\n",
    "\n",
    "> Getting rid of all the chunks that are smaller than the context size wasn’t a big issue here because we’re using small context windows. As you increase the context size (or if you have a corpus of short documents), the fraction of chunks that are thrown away will also grow. A more efficient way to prepare the data is to **join all the tokenized samples** in a batch with an `eos_token_id` token in between, and then perform the chunking on the concatenated sequences. Note that you’ll want to set **truncation=False** and remove the other arguments from the tokenizer to get the full sequence of token IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(elements):\n",
    "    \"\"\"\n",
    "    Tokenize the content of the elements throwing away the overflowing tokens\n",
    "    \"\"\"\n",
    "    outputs = tokenizer(  # Tokenize the samples to input_ids\n",
    "        elements[\"content\"],\n",
    "        truncation=True,  # Truncate the content\n",
    "        max_length=context_length,  # Set the maximum length per chunk\n",
    "        return_overflowing_tokens=True,  # Don't discard overflowing tokens\n",
    "        return_length=True,  # Return the length of each chunk\n",
    "    )\n",
    "\n",
    "    input_batch = []\n",
    "    # Iterate over each chunk and its length\n",
    "    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
    "        # Discard chunks that are not chunk_length\n",
    "        if length == context_length:\n",
    "            input_batch.append(input_ids)\n",
    "\n",
    "    return {\"input_ids\": input_batch}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_joining(elements):\n",
    "    outputs = tokenizer(\n",
    "        elements[\"content\"],\n",
    "        truncation=False\n",
    "    )\n",
    "\n",
    "    all_input_ids = []\n",
    "    for iid in outputs[\"input_ids\"]:\n",
    "        all_input_ids.extend(iid + [tokenizer.eos_token_id])\n",
    "\n",
    "    # We drop the last chunk if it's smaller than chunk_size\n",
    "    total_length = len(all_input_ids)\n",
    "    total_length = (total_length // context_length) * context_length\n",
    "\n",
    "    chunks = []\n",
    "    for i in range(0, total_length, context_length):\n",
    "        chunks.append(all_input_ids[i:i + context_length])\n",
    "\n",
    "    return {\"input_ids\": chunks}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae7bdae6013c424e966b51f2654c12d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/27000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1809 > 1024). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13fdbcb5558444fab2aa20531e9d734d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 759667\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['input_ids'],\n",
       "        num_rows: 84454\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = raw_datasets.map(\n",
    "    tokenize_joining,\n",
    "    batched=True,\n",
    "    # Remove columns that are not used\n",
    "    remove_columns=raw_datasets[\"train\"].column_names\n",
    ")\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "97237376"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the number of tokens in the dataset\n",
    "total_tokens = tokenized_datasets[\"train\"].num_rows * context_length\n",
    "# display the number of tokens in billions\n",
    "total_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have 25.4 million examples with 128 tokens each, which corresponds to about 32 million tokens in total. For reference, OpenAI’s GPT-3 and Codex models are trained on 300 and 100 billion tokens, respectively, where the Codex models are initialized from the GPT-3 checkpoints. Our goal in this section is not to compete with these models, which can generate long, coherent texts, but to create a scaled-down version providing a quick autocomplete function for data scientists.\n",
    "\n",
    "Now that we have the dataset ready, let’s set up the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing a new model\n",
    "\n",
    "Our first step is to freshly initialize a GPT-2 model. We’ll use the same configuration for our model as for the small GPT-2 model, so we load the pretrained configuration, make sure that the tokenizer size matches the model vocabulary size and pass the `bos` and `eos` (beginning and end of sequence) token IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, GPT2LMHeadModel, AutoConfig\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    vocab_size=len(tokenizer),\n",
    "    n_ctx=context_length,\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that configuration, we can load a new model. Note that this is the first time **we don’t use the `from_pretrained()`** function, since we’re actually initializing a model ourself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 size: 124.2M parameters\n"
     ]
    }
   ],
   "source": [
    "model = GPT2LMHeadModel(config)\n",
    "model_size = sum(t.numel() for t in model.parameters())\n",
    "print(f\"GPT-2 size: {model_size/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model has 124M parameters that we’ll have to tune. Before we can start training, we need to set up a data collator that will take care of creating the batches. We can use the `DataCollatorForLanguageModeling` collator, which is designed specifically for **language modeling** (as the name subtly suggests). Besides stacking and padding batches, it also takes care of creating the language model labels — in causal language modeling the **inputs serve as labels too (just shifted by one element)**, and this data collator creates them on the fly during training so we don’t need to duplicate the input_ids.\n",
    "\n",
    "> Note that `DataCollatorForLanguageModeling` supports both masked language modeling (MLM) and causal language modeling (CLM). By default it prepares data for MLM, but we can switch to CLM by setting the argument `mlm=False`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s have a look at an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids shape: torch.Size([5, 128])\n",
      "attention_mask shape: torch.Size([5, 128])\n",
      "labels shape: torch.Size([5, 128])\n"
     ]
    }
   ],
   "source": [
    "out = data_collator([tokenized_datasets[\"train\"][i] for i in range(5)])\n",
    "for key in out:\n",
    "    print(f\"{key} shape: {out[key].shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the examples have been stacked and all the tensors have the same shape. **Notice next that the inputs and labels are the same, they are not shifted!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(3), tensor(3))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display first example, first token input id and label\n",
    "out[\"input_ids\"][0][0], out[\"labels\"][0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ⚠️ **Shifting the inputs and labels to align them happens inside the model, so the data collator just copies the inputs to create the labels.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trainer\n",
    "\n",
    "All that’s left to do is configure the training arguments and fire up the Trainer. We’ll use a cosine learning rate schedule with some warmup and an effective batch size of 256 (`per_device_train_batch_size` * `gradient_accumulation_steps`). Gradient accumulation is used when a single batch does not fit into memory, and incrementally builds up the gradient through several forward/backward passes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "output_dir = f\"tmp/clm-codeparrot_ds-{context_length}\"\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=5_000,\n",
    "    logging_steps=5_000,\n",
    "    gradient_accumulation_steps=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.1,\n",
    "    warmup_steps=1_000,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    learning_rate=5e-4,\n",
    "    save_steps=5_000,\n",
    "    fp16=True,\n",
    "    push_to_hub=True,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"valid\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can just start the Trainer and wait for training to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmarioparreno\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.6 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/maparla/Desktop/NLPJourney/wandb/run-20240813_134643-5bdmxii2</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/marioparreno/huggingface/runs/5bdmxii2' target=\"_blank\">tmp/clm-codeparrot_ds-128</a></strong> to <a href='https://wandb.ai/marioparreno/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/marioparreno/huggingface' target=\"_blank\">https://wandb.ai/marioparreno/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/marioparreno/huggingface/runs/5bdmxii2' target=\"_blank\">https://wandb.ai/marioparreno/huggingface/runs/5bdmxii2</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f140a730db84cf39e5b16cfe4a15d6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5935 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7612, 'grad_norm': 0.5376766324043274, 'learning_rate': 4.299309564517404e-05, 'epoch': 0.84}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6441509257d4692bca2a224907a7876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5279 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8816652297973633, 'eval_runtime': 204.8242, 'eval_samples_per_second': 412.324, 'eval_steps_per_second': 25.773, 'epoch': 0.84}\n",
      "{'train_runtime': 5426.9103, 'train_samples_per_second': 139.981, 'train_steps_per_second': 1.094, 'train_loss': 2.622534117983888, 'epoch': 1.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=5935, training_loss=2.622534117983888, metrics={'train_runtime': 5426.9103, 'train_samples_per_second': 139.981, 'train_steps_per_second': 1.094, 'total_flos': 4.9623733518336e+16, 'train_loss': 2.622534117983888, 'epoch': 1.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code generation with a pipeline\n",
    "\n",
    "Now is the moment of truth: let’s see how well the trained model actually works! We can see in the logs that the loss went down steadily, but to put the model to the test let’s take a look at how well it works on some prompts. To do that we’ll wrap the model in a text generation pipeline, and we’ll put it on the GPU for fast generations if there is one available:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=output_dir + '/checkpoint-1996',\n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# create some data\n",
      "x = np.random.randn(100)\n",
      "y = np.random.randn(100)\n",
      "\n",
      "# create scatter plot with x, y\n",
      "Z = plt.scatter(xx[:, 0], yy[:, 1\n"
     ]
    }
   ],
   "source": [
    "txt = \"\"\"\\\n",
    "# create some data\n",
    "x = np.random.randn(100)\n",
    "y = np.random.randn(100)\n",
    "\n",
    "# create scatter plot with x, y\n",
    "\"\"\"\n",
    "print(pipe(txt, num_return_sequences=1)[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# create some data\n",
      "x = np.random.randn(100)\n",
      "y = np.random.randn(100)\n",
      "\n",
      "# create dataframe from x and y\n",
      "y = x.reshape((-1, 1))\n",
      "x1 =\n"
     ]
    }
   ],
   "source": [
    "txt = \"\"\"\\\n",
    "# create some data\n",
    "x = np.random.randn(100)\n",
    "y = np.random.randn(100)\n",
    "\n",
    "# create dataframe from x and y\n",
    "\"\"\"\n",
    "print(pipe(txt, num_return_sequences=1)[0][\"generated_text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at these few examples, it seems that the model has learned some of the syntax of the Python data science stack (of course, we would need to evaluate it more thoroughly before deploying the model in the real world). Sometimes it requires more customization of the model training to achieve the necessary performance for a given use case, however. For example, what if we would like to dynamically update the batch size or have a conditional training loop that skips bad examples on the fly? One option would be to subclass the Trainer and add the necessary changes, but sometimes it’s simpler to write the training loop from scratch. Check the [Accelerate Notebook](pt_causal_scratch.ipynb)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
